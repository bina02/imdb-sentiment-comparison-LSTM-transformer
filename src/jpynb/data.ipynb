{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0cB5xv+Xn0f7flSEBCgFM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#1. download IMDB dataset"],"metadata":{"id":"S_wamxYo44On"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"184oaVtV2bqS","executionInfo":{"status":"ok","timestamp":1768383483495,"user_tz":-540,"elapsed":6140,"user":{"displayName":"HYEONBIN HWANG","userId":"08318351351104504376"}},"outputId":"e91ed163-9e6b-4754-9926-9e5d449f586d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","source":["from datasets import load_dataset\n","imdb = load_dataset('imdb')\n","train_data = imdb['train']\n","test_data = imdb['test']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3a0943d1f85b4e33ae2f4e9524305ab5","2899ef6e136b4894a95b32d47909f22b","7c6131a7e4d84d6fb824618f94f43ac7","1bf766db2a894aa49fa5f779a67c3e20","d0da2625a4894dfdafc1cef68c817a5e","6a51dafc68194a6a972d90b43f40cd87","9278f44de1294e9d94dd295c1bfea87a","17a6d648b7c04e369cd53c8aaadf54c1","45fac2fe5c244f44a2648a964957a58f","44d86cd9cabe4911b48d599dc173b879","316f9152b64e4357a79616d14a22ec91"]},"id":"yI8yoMTD2gBm","executionInfo":{"status":"ok","timestamp":1768387837952,"user_tz":-540,"elapsed":1829,"user":{"displayName":"HYEONBIN HWANG","userId":"08318351351104504376"}},"outputId":"4cd3b28b-fa49-4780-c82b-5d427951851f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0943d1f85b4e33ae2f4e9524305ab5"}},"metadata":{}}]},{"cell_type":"markdown","source":["#2. Make vocab Dictionary and sentencepiece model"],"metadata":{"id":"Ct11JSUo48QS"}},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjUZ2rJ03uSb","executionInfo":{"status":"ok","timestamp":1768383782989,"user_tz":-540,"elapsed":4581,"user":{"displayName":"HYEONBIN HWANG","userId":"08318351351104504376"}},"outputId":"54bd58b2-8b5f-4b80-8b31-39b687f864b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n"]}]},{"cell_type":"code","source":["\"\"\"\n","I chose SentencePiece as the tokenizer because it is a subword-based tokenizer.\n","This significantly reduces the occurrence of the <unk> token.\n","\"\"\"\n","\n","import sentencepiece as spm\n","with open('/content/drive/MyDrive/github/imdb-sentiment-comparison-rnn-transformer/src/sentencepiece/imdb.txt', 'w', encoding='utf-8') as f:\n","  for item in train_data:\n","    f.write(item['text'] + '\\n')"],"metadata":{"id":"Qtdbd5nJ34sW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","The reason I chose 20,000 as the vocabulary size is that the IMDb dataset has long reviews and a wide variety of expressions.\n","\"\"\"\n","spm.SentencePieceTrainer.train(\n","    input = '/content/drive/MyDrive/github/imdb-sentiment-comparison-rnn-transformer/src/sentencepiece/imdb.txt',\n","    model_prefix = '/content/drive/MyDrive/github/imdb-sentiment-comparison-rnn-transformer/src/sentencepiece/imdb',\n","    vocab_size = 20000,\n","    unk_id=0,\n","    pad_id=1,\n","    bos_id=2,\n","    eos_id=3\n",")"],"metadata":{"id":"gM3x7ahb7CxY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sp = spm.SentencePieceProcessor()\n","sp.load('/content/drive/MyDrive/github/imdb-sentiment-comparison-rnn-transformer/src/sentencepiece/imdb.model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yx1IQkjC9Bvs","executionInfo":{"status":"ok","timestamp":1768387836122,"user_tz":-540,"elapsed":17,"user":{"displayName":"HYEONBIN HWANG","userId":"08318351351104504376"}},"outputId":"43044bec-9f50-41ad-b8ec-d69bcc10424f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["#3. Make Dataset&Dataloader"],"metadata":{"id":"e_G7kHHFAAHB"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class imdbDataset(Dataset):\n","  def __init__(self, data):\n","    self.data = data\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    text = torch.tensor(sp.encode(self.data[idx]['text']), dtype=torch.long)\n","    label = torch.tensor(self.data[idx]['label'], dtype=torch.float) #Use BCEWithLogitsLoss, so the target dtype should be float\n","    return text, label\n","\n","def collate_fn(batch):\n","  texts, labels = zip(*batch)\n","  lengths = torch.tensor([len(text) for text in texts], dtype=torch.long)\n","  texts = pad_sequence(texts, batch_first=True, padding_value=sp.pad_id())\n","  labels = torch.stack(labels)\n","  return texts, lengths, labels\n","\n","train_loader = DataLoader(imdbDataset(train_data), batch_size=64, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(imdbDataset(test_data), batch_size=32, collate_fn=collate_fn)"],"metadata":{"id":"iuEyihfkAvBj"},"execution_count":null,"outputs":[]}]}